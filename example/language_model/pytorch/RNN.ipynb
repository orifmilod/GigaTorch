{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design criteria for modeling sequential data: \n",
    "1. Handle variable-lenght sequence.\n",
    "2. Track long-term depedencies.\n",
    "3. Maintain information about order.\n",
    "4. Share params accross the sequence.\n",
    "\n",
    "\n",
    "RNN can fullfit these criteria and be used for sequence modeling.\n",
    "\n",
    "For instance, we can use it for:\n",
    "    - Many To One relation, where we take a sequence of tokens and then product a single reuslt, such as Sentiment Classification: where we take list of words\n",
    "    and predict the sentiment of the sentence.\n",
    "    - One to Many: Text generation: We input an image and the RNN would produce what the picture contains.\n",
    "    - Many to Many: Tanslation or Forecasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CBOW model architecture tries to predict the current target word (the center word) based on the source context words. \n",
    "\n",
    "Considering a simple sentence, **“the quick brown fox jumps over the lazy dog”**, this can be pairs of `(context_window, target_word)` where if we consider a context window of size 2, we have examples like ([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy) and so on. Thus the model tries to predict the target_word based on the context_window words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
